{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72b17a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T15:25:13.168675Z",
     "start_time": "2023-06-13T15:25:13.103796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext dotenv\\n%dotenv\\nfrom IPython.core.interactiveshell import InteractiveShell\\nfrom IPython.display import Image, display\\n\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\";\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext dotenv\\n%dotenv\\nfrom IPython.core.interactiveshell import InteractiveShell\\nfrom IPython.display import Image, display\\n\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import Image, display\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b506fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T15:25:14.998423Z",
     "start_time": "2023-06-13T15:25:13.463667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import tempfile\\nimport shutil\\nimport glob\\nimport os\\n\\n# import cv2\\nimport av\\nimport PIL\\n\\nfrom tqdm.notebook import tqdm\\n\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\n\\n# import plotnine as p9\\nimport pandas as pd\\n\\nimport libem\\n\\n%matplotlib inline\\n\\n\\ndef show_im(p):\\n    display(Image(filename=p))\";\n",
       "                var nbb_formatted_code = \"import tempfile\\nimport shutil\\nimport glob\\nimport os\\n\\n# import cv2\\nimport av\\nimport PIL\\n\\nfrom tqdm.notebook import tqdm\\n\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\n\\n# import plotnine as p9\\nimport pandas as pd\\n\\nimport libem\\n\\n%matplotlib inline\\n\\n\\ndef show_im(p):\\n    display(Image(filename=p))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# import cv2\n",
    "import av\n",
    "import PIL\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import plotnine as p9\n",
    "import pandas as pd\n",
    "\n",
    "import libem\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def show_im(p):\n",
    "    display(Image(filename=p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999a29f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T15:25:19.433108Z",
     "start_time": "2023-06-13T15:25:15.061327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\\n\\nsam_checkpoint = \\\"/home/mike/Downloads/sam_vit_h_4b8939.pth\\\"\\nmodel_type = \\\"vit_h\\\"\\n\\ndevice = \\\"cuda\\\"\\n\\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\\n_ = sam.to(device=device)\\n\\n\\nmask_generator = SamAutomaticMaskGenerator(\\n    model=sam,\\n    # points_per_side=128,\\n    # points_per_batch=32,\\n    # pred_iou_thresh=0.86,\\n    # stability_score_thresh=0.92,\\n    # crop_n_layers=1,\\n    # crop_n_points_downscale_factor=2,\\n    # min_mask_region_area=20,  # Requires open-cv to run post-processing\\n)\";\n",
       "                var nbb_formatted_code = \"from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\\n\\nsam_checkpoint = \\\"/home/mike/Downloads/sam_vit_h_4b8939.pth\\\"\\nmodel_type = \\\"vit_h\\\"\\n\\ndevice = \\\"cuda\\\"\\n\\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\\n_ = sam.to(device=device)\\n\\n\\nmask_generator = SamAutomaticMaskGenerator(\\n    model=sam,\\n    # points_per_side=128,\\n    # points_per_batch=32,\\n    # pred_iou_thresh=0.86,\\n    # stability_score_thresh=0.92,\\n    # crop_n_layers=1,\\n    # crop_n_points_downscale_factor=2,\\n    # min_mask_region_area=20,  # Requires open-cv to run post-processing\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"/home/mike/Downloads/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "_ = sam.to(device=device)\n",
    "\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    # points_per_side=128,\n",
    "    # points_per_batch=32,\n",
    "    # pred_iou_thresh=0.86,\n",
    "    # stability_score_thresh=0.92,\n",
    "    # crop_n_layers=1,\n",
    "    # crop_n_points_downscale_factor=2,\n",
    "    # min_mask_region_area=20,  # Requires open-cv to run post-processing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de65faaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T15:25:20.834823Z",
     "start_time": "2023-06-13T15:25:20.784414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"config = {\\n    \\\"SPEED\\\": dict(\\n        sel=(-0.3, 1.2, 1.2, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"WATTS\\\": dict(\\n        sel=(-0.3, 1.2, 0.8, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"CADENCE\\\": dict(\\n        sel=(0, 1.2, 0.20, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"DISTANCE\\\": dict(\\n        sel=(0, 1.2, 0.7, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"1x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"TIME\\\": dict(\\n        sel=(-1.2, 1.2, 1.45, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"CALORIES\\\": dict(\\n        sel=(0, 1.2, 0.2, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n}\\n\\n\\ndef initial_ocr_and_crop(img):\\n    fdf = libem.locate_display(np.asarray(img))\\n    rec = libem.crop_to_numbers(fdf)\\n\\n    crop_left, crop_right, crop_top, crop_bottom = (\\n        rec[\\\"left\\\"],\\n        rec[\\\"right\\\"],\\n        rec[\\\"top\\\"],\\n        rec[\\\"bottom\\\"],\\n    )\\n    crop_width = abs(crop_left - crop_right)\\n    crop_height = abs(crop_top - crop_bottom)\\n    crop_left -= int(round(crop_width * 0.1))\\n    crop_right += int(round(crop_width * 0.1))\\n    crop_bottom += int(round(crop_height * 0.5))\\n    cropped_img = img.crop((crop_left, crop_top, crop_right, crop_bottom))\\n    resize_height = int(cropped_img.height * (rec[\\\"resize_width\\\"] / cropped_img.width))\\n    resized_img = cropped_img.resize(\\n        (rec[\\\"resize_width\\\"], resize_height), PIL.Image.LANCZOS\\n    )\\n    rotated_img = resized_img.rotate(rec[\\\"angle\\\"], PIL.Image.BICUBIC)\\n    # rotated_img\\n\\n    # matches = libem.locate_numbers(\\n    #     phase1_results_df.query(\\\"frame == @base\\\").assign(\\n    #         bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\\n    #     )\\n    # )\\n\\n    ocr = libem.get_ocr()\\n    ocr_df = libem.paddle_results_to_df(ocr.ocr(np.asarray(rotated_img), cls=True)[0])\\n\\n    return ocr_df, rotated_img\\n\\n\\ndef show_anns_df(anns):\\n    if len(anns) == 0:\\n        return\\n    anns = anns.sort_values(\\\"area\\\", ascending=False)\\n\\n    first_mask = anns.head(1).squeeze()\\n\\n    img = np.zeros_like(first_mask.segmentation).astype(np.bool_)\\n    for ann in anns.itertuples():\\n        img |= ann.segmentation\\n\\n    img = ~img\\n\\n    return PIL.Image.fromarray(img)\\n\\n\\ndef get_text(ppocr_result):\\n    try:\\n        return ppocr_result[0][0][-1][0]\\n    except IndexError:\\n        return None\\n\\n\\ndef second_round(ocr_df, img):\\n    #     matches = libem.locate_numbers(\\n    #         ocr_df.assign(bbox=lambda f: f.bbox.apply(libem.make_polygons_2d))\\n    #     )\\n    ocr = libem.get_ocr()\\n    records = []\\n    #     print(f\\\"{matches=}\\\")\\n    for landmark in config:\\n        landmark\\n\\n        cfg = config[landmark]\\n\\n        # im = PIL.Image.open(base)\\n        # base = os.path.basename(frame)\\n        bbox = ocr_df.query(\\\"inference_text == @landmark\\\").bbox.squeeze()\\n\\n        try:\\n            im, out = libem.ssocr_subimage(img, bbox, cfg[\\\"sel\\\"], cfg[\\\"ssocr_conf\\\"])\\n        except:\\n            record = dict(\\n                landmark=landmark,\\n                pp1=\\\"\\\",\\n                ss1=\\\"\\\",\\n                pp2=\\\"\\\",\\n                ss2=\\\"\\\",\\n            )\\n            records.append(record)\\n            continue\\n\\n        ssocr1 = out\\n        ppocr1 = get_text(ocr.ocr(np.asarray(im), cls=True))\\n\\n        _df = pd.DataFrame(mask_generator.generate(np.asarray(im)))\\n        _df[[\\\"left\\\", \\\"top\\\", \\\"width\\\", \\\"height\\\"]] = _df[\\\"bbox\\\"].apply(pd.Series)\\n        _df = _df.query(\\\"area.between(100, 2000)\\\").query(\\\"width < 100\\\")\\n\\n        im_sam = show_anns_df(_df).convert(\\\"RGB\\\")\\n\\n        ssocr2 = libem.run_ssocr(np.asarray(im_sam), *cfg[\\\"ssocr_conf\\\"])\\n        ppocr2 = get_text(ocr.ocr(np.asarray(im_sam), cls=True))\\n\\n        record = dict(\\n            landmark=landmark,\\n            pp1=ppocr1,\\n            ss1=ssocr1,\\n            pp2=ppocr2,\\n            ss2=ssocr2,\\n        )\\n        records.append(record)\\n\\n    return pd.DataFrame(records)\";\n",
       "                var nbb_formatted_code = \"config = {\\n    \\\"SPEED\\\": dict(\\n        sel=(-0.3, 1.2, 1.2, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"WATTS\\\": dict(\\n        sel=(-0.3, 1.2, 0.8, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"CADENCE\\\": dict(\\n        sel=(0, 1.2, 0.20, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"DISTANCE\\\": dict(\\n        sel=(0, 1.2, 0.7, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"1x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"TIME\\\": dict(\\n        sel=(-1.2, 1.2, 1.45, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n    \\\"CALORIES\\\": dict(\\n        sel=(0, 1.2, 0.2, 3.5),\\n        ssocr_conf=(\\n            {\\\"number-digits\\\": -1, \\\"threshold\\\": 30, \\\"min-char-dims\\\": \\\"5x50\\\"},\\n            [],\\n        ),\\n    ),\\n}\\n\\n\\ndef initial_ocr_and_crop(img):\\n    fdf = libem.locate_display(np.asarray(img))\\n    rec = libem.crop_to_numbers(fdf)\\n\\n    crop_left, crop_right, crop_top, crop_bottom = (\\n        rec[\\\"left\\\"],\\n        rec[\\\"right\\\"],\\n        rec[\\\"top\\\"],\\n        rec[\\\"bottom\\\"],\\n    )\\n    crop_width = abs(crop_left - crop_right)\\n    crop_height = abs(crop_top - crop_bottom)\\n    crop_left -= int(round(crop_width * 0.1))\\n    crop_right += int(round(crop_width * 0.1))\\n    crop_bottom += int(round(crop_height * 0.5))\\n    cropped_img = img.crop((crop_left, crop_top, crop_right, crop_bottom))\\n    resize_height = int(cropped_img.height * (rec[\\\"resize_width\\\"] / cropped_img.width))\\n    resized_img = cropped_img.resize(\\n        (rec[\\\"resize_width\\\"], resize_height), PIL.Image.LANCZOS\\n    )\\n    rotated_img = resized_img.rotate(rec[\\\"angle\\\"], PIL.Image.BICUBIC)\\n    # rotated_img\\n\\n    # matches = libem.locate_numbers(\\n    #     phase1_results_df.query(\\\"frame == @base\\\").assign(\\n    #         bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\\n    #     )\\n    # )\\n\\n    ocr = libem.get_ocr()\\n    ocr_df = libem.paddle_results_to_df(ocr.ocr(np.asarray(rotated_img), cls=True)[0])\\n\\n    return ocr_df, rotated_img\\n\\n\\ndef show_anns_df(anns):\\n    if len(anns) == 0:\\n        return\\n    anns = anns.sort_values(\\\"area\\\", ascending=False)\\n\\n    first_mask = anns.head(1).squeeze()\\n\\n    img = np.zeros_like(first_mask.segmentation).astype(np.bool_)\\n    for ann in anns.itertuples():\\n        img |= ann.segmentation\\n\\n    img = ~img\\n\\n    return PIL.Image.fromarray(img)\\n\\n\\ndef get_text(ppocr_result):\\n    try:\\n        return ppocr_result[0][0][-1][0]\\n    except IndexError:\\n        return None\\n\\n\\ndef second_round(ocr_df, img):\\n    #     matches = libem.locate_numbers(\\n    #         ocr_df.assign(bbox=lambda f: f.bbox.apply(libem.make_polygons_2d))\\n    #     )\\n    ocr = libem.get_ocr()\\n    records = []\\n    #     print(f\\\"{matches=}\\\")\\n    for landmark in config:\\n        landmark\\n\\n        cfg = config[landmark]\\n\\n        # im = PIL.Image.open(base)\\n        # base = os.path.basename(frame)\\n        bbox = ocr_df.query(\\\"inference_text == @landmark\\\").bbox.squeeze()\\n\\n        try:\\n            im, out = libem.ssocr_subimage(img, bbox, cfg[\\\"sel\\\"], cfg[\\\"ssocr_conf\\\"])\\n        except:\\n            record = dict(\\n                landmark=landmark,\\n                pp1=\\\"\\\",\\n                ss1=\\\"\\\",\\n                pp2=\\\"\\\",\\n                ss2=\\\"\\\",\\n            )\\n            records.append(record)\\n            continue\\n\\n        ssocr1 = out\\n        ppocr1 = get_text(ocr.ocr(np.asarray(im), cls=True))\\n\\n        _df = pd.DataFrame(mask_generator.generate(np.asarray(im)))\\n        _df[[\\\"left\\\", \\\"top\\\", \\\"width\\\", \\\"height\\\"]] = _df[\\\"bbox\\\"].apply(pd.Series)\\n        _df = _df.query(\\\"area.between(100, 2000)\\\").query(\\\"width < 100\\\")\\n\\n        im_sam = show_anns_df(_df).convert(\\\"RGB\\\")\\n\\n        ssocr2 = libem.run_ssocr(np.asarray(im_sam), *cfg[\\\"ssocr_conf\\\"])\\n        ppocr2 = get_text(ocr.ocr(np.asarray(im_sam), cls=True))\\n\\n        record = dict(\\n            landmark=landmark,\\n            pp1=ppocr1,\\n            ss1=ssocr1,\\n            pp2=ppocr2,\\n            ss2=ssocr2,\\n        )\\n        records.append(record)\\n\\n    return pd.DataFrame(records)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"SPEED\": dict(\n",
    "        sel=(-0.3, 1.2, 1.2, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"5x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"WATTS\": dict(\n",
    "        sel=(-0.3, 1.2, 0.8, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"5x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CADENCE\": dict(\n",
    "        sel=(0, 1.2, 0.20, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"5x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"DISTANCE\": dict(\n",
    "        sel=(0, 1.2, 0.7, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"1x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"TIME\": dict(\n",
    "        sel=(-1.2, 1.2, 1.45, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"5x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CALORIES\": dict(\n",
    "        sel=(0, 1.2, 0.2, 3.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 30, \"min-char-dims\": \"5x50\"},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def initial_ocr_and_crop(img):\n",
    "    fdf = libem.locate_display(np.asarray(img))\n",
    "    rec = libem.crop_to_numbers(fdf)\n",
    "\n",
    "    crop_left, crop_right, crop_top, crop_bottom = (\n",
    "        rec[\"left\"],\n",
    "        rec[\"right\"],\n",
    "        rec[\"top\"],\n",
    "        rec[\"bottom\"],\n",
    "    )\n",
    "    crop_width = abs(crop_left - crop_right)\n",
    "    crop_height = abs(crop_top - crop_bottom)\n",
    "    crop_left -= int(round(crop_width * 0.1))\n",
    "    crop_right += int(round(crop_width * 0.1))\n",
    "    crop_bottom += int(round(crop_height * 0.5))\n",
    "    cropped_img = img.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "    resize_height = int(cropped_img.height * (rec[\"resize_width\"] / cropped_img.width))\n",
    "    resized_img = cropped_img.resize(\n",
    "        (rec[\"resize_width\"], resize_height), PIL.Image.LANCZOS\n",
    "    )\n",
    "    rotated_img = resized_img.rotate(rec[\"angle\"], PIL.Image.BICUBIC)\n",
    "    # rotated_img\n",
    "\n",
    "    # matches = libem.locate_numbers(\n",
    "    #     phase1_results_df.query(\"frame == @base\").assign(\n",
    "    #         bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    ocr = libem.get_ocr()\n",
    "    ocr_df = libem.paddle_results_to_df(ocr.ocr(np.asarray(rotated_img), cls=True)[0])\n",
    "\n",
    "    return ocr_df, rotated_img\n",
    "\n",
    "\n",
    "def show_anns_df(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    anns = anns.sort_values(\"area\", ascending=False)\n",
    "\n",
    "    first_mask = anns.head(1).squeeze()\n",
    "\n",
    "    img = np.zeros_like(first_mask.segmentation).astype(np.bool_)\n",
    "    for ann in anns.itertuples():\n",
    "        img |= ann.segmentation\n",
    "\n",
    "    img = ~img\n",
    "\n",
    "    return PIL.Image.fromarray(img)\n",
    "\n",
    "\n",
    "def get_text(ppocr_result):\n",
    "    try:\n",
    "        return ppocr_result[0][0][-1][0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def second_round(ocr_df, img):\n",
    "    #     matches = libem.locate_numbers(\n",
    "    #         ocr_df.assign(bbox=lambda f: f.bbox.apply(libem.make_polygons_2d))\n",
    "    #     )\n",
    "    ocr = libem.get_ocr()\n",
    "    records = []\n",
    "    #     print(f\"{matches=}\")\n",
    "    for landmark in config:\n",
    "        landmark\n",
    "\n",
    "        cfg = config[landmark]\n",
    "\n",
    "        # im = PIL.Image.open(base)\n",
    "        # base = os.path.basename(frame)\n",
    "        bbox = ocr_df.query(\"inference_text == @landmark\").bbox.squeeze()\n",
    "\n",
    "        try:\n",
    "            im, out = libem.ssocr_subimage(img, bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "        except:\n",
    "            record = dict(\n",
    "                landmark=landmark,\n",
    "                pp1=\"\",\n",
    "                ss1=\"\",\n",
    "                pp2=\"\",\n",
    "                ss2=\"\",\n",
    "            )\n",
    "            records.append(record)\n",
    "            continue\n",
    "\n",
    "        ssocr1 = out\n",
    "        ppocr1 = get_text(ocr.ocr(np.asarray(im), cls=True))\n",
    "\n",
    "        _df = pd.DataFrame(mask_generator.generate(np.asarray(im)))\n",
    "        _df[[\"left\", \"top\", \"width\", \"height\"]] = _df[\"bbox\"].apply(pd.Series)\n",
    "        _df = _df.query(\"area.between(100, 2000)\").query(\"width < 100\")\n",
    "\n",
    "        im_sam = show_anns_df(_df).convert(\"RGB\")\n",
    "\n",
    "        ssocr2 = libem.run_ssocr(np.asarray(im_sam), *cfg[\"ssocr_conf\"])\n",
    "        ppocr2 = get_text(ocr.ocr(np.asarray(im_sam), cls=True))\n",
    "\n",
    "        record = dict(\n",
    "            landmark=landmark,\n",
    "            pp1=ppocr1,\n",
    "            ss1=ssocr1,\n",
    "            pp2=ppocr2,\n",
    "            ss2=ssocr2,\n",
    "        )\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb67b7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T15:26:03.248Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b18dc995484e0386cf2ec38afbdcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing frames:   0%|          | 0/12224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote output after index: [99]\n",
      "Wrote output after index: [199]\n",
      "Wrote output after index: [299]\n",
      "Wrote output after index: [399]\n",
      "Wrote output after index: [499]\n",
      "Wrote output after index: [599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-13 17:04:27,751] [ WARNING] process.py:81 - Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote output after index: [699]\n",
      "Wrote output after index: [799]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-13 19:17:16,636] [ WARNING] process.py:81 - Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '!']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote output after index: [899]\n",
      "Wrote output after index: [999]\n",
      "Wrote output after index: [1099]\n",
      "Wrote output after index: [1199]\n",
      "Wrote output after index: [1299]\n",
      "Wrote output after index: [1399]\n",
      "Wrote output after index: [1499]\n",
      "Wrote output after index: [1599]\n",
      "Wrote output after index: [1699]\n",
      "Wrote output after index: [1799]\n",
      "Wrote output after index: [1899]\n",
      "Wrote output after index: [1999]\n",
      "Wrote output after index: [2099]\n",
      "Wrote output after index: [2199]\n",
      "Wrote output after index: [2299]\n",
      "Wrote output after index: [2399]\n",
      "Wrote output after index: [2499]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-14 16:39:00,786] [ WARNING] process.py:81 - Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '-']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote output after index: [2599]\n",
      "Wrote output after index: [2699]\n",
      "Wrote output after index: [2799]\n",
      "Wrote output after index: [2899]\n",
      "Wrote output after index: [2999]\n",
      "Wrote output after index: [3099]\n",
      "Wrote output after index: [3199]\n",
      "Wrote output after index: [3299]\n",
      "Wrote output after index: [3399]\n",
      "Wrote output after index: [3499]\n",
      "Wrote output after index: [3599]\n",
      "Wrote output after index: [3699]\n",
      "Wrote output after index: [3799]\n",
      "Wrote output after index: [3899]\n",
      "Wrote output after index: [3999]\n",
      "Wrote output after index: [4099]\n",
      "Wrote output after index: [4199]\n",
      "Wrote output after index: [4299]\n",
      "Wrote output after index: [4399]\n",
      "Wrote output after index: [4499]\n",
      "Wrote output after index: [4599]\n",
      "Wrote output after index: [4699]\n",
      "Wrote output after index: [4799]\n"
     ]
    }
   ],
   "source": [
    "ctr = av.open(\"/bucket/exercise-machina/IMG_1392.MOV\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# lo, hi = 2500, 3500\n",
    "lo, hi = 0, 12224\n",
    "# Create a tqdm object\n",
    "progress_bar = tqdm(total=(hi - lo), desc=\"Processing frames\")\n",
    "\n",
    "for ix, frame in enumerate(ctr.decode(video=0)):\n",
    "    if ix < lo:\n",
    "        continue\n",
    "    if ix >= hi:\n",
    "        break\n",
    "\n",
    "    image = frame.to_image()\n",
    "\n",
    "    ocr_df, sub_image = initial_ocr_and_crop(image)\n",
    "    ocr2_df = second_round(ocr_df, sub_image).assign(frame=ix)\n",
    "\n",
    "    _ = progress_bar.update(1)  # Update the progress bar by one iteration\n",
    "    frames.append(ocr2_df)\n",
    "\n",
    "    if len(frames) == 100:\n",
    "        frames = pd.concat(frames)\n",
    "        frames.to_csv(f\"frames.{ix:06d}.csv\", index=False)\n",
    "        print(f\"Wrote output after index: [{ix}]\")\n",
    "        frames = []\n",
    "\n",
    "progress_bar.close()  # Close the progress bar at the end of the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51250d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T23:37:28.714800Z",
     "start_time": "2023-06-11T23:36:46.855004Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ocr_df, sub_image = initial_ocr_and_crop(image)\n",
    "ocr_df\n",
    "sub_image\n",
    "ocr2_df = second_round(ocr_df, sub_image).assign(frame=ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eaf1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T17:40:47.672414Z",
     "start_time": "2023-06-11T17:40:47.633087Z"
    }
   },
   "outputs": [],
   "source": [
    "ocr2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec14dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:01:28.806044Z",
     "start_time": "2023-06-10T14:01:28.763855Z"
    }
   },
   "outputs": [],
   "source": [
    "frames_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bda6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:03:40.387538Z",
     "start_time": "2023-06-10T14:03:40.357212Z"
    }
   },
   "outputs": [],
   "source": [
    "frames_df.query(\"landmark == 'SPEED'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7274c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.403364Z",
     "start_time": "2023-06-09T22:56:23.403347Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fdf = libem.locate_display(frame.to_ndarray())\n",
    "rec = libem.crop_to_numbers(fdf)\n",
    "\n",
    "\n",
    "crop_left, crop_right, crop_top, crop_bottom = (\n",
    "    rec[\"left\"],\n",
    "    rec[\"right\"],\n",
    "    rec[\"top\"],\n",
    "    rec[\"bottom\"],\n",
    ")\n",
    "crop_width = abs(crop_left - crop_right)\n",
    "crop_height = abs(crop_top - crop_bottom)\n",
    "crop_left -= int(round(crop_width * 0.1))\n",
    "crop_right += int(round(crop_width * 0.1))\n",
    "crop_bottom += int(round(crop_height * 0.5))\n",
    "cropped_img = img.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "resize_height = int(cropped_img.height * (rec[\"resize_width\"] / cropped_img.width))\n",
    "resized_img = cropped_img.resize(\n",
    "    (rec[\"resize_width\"], resize_height), PIL.Image.LANCZOS\n",
    ")\n",
    "rotated_img = resized_img.rotate(rec[\"angle\"], PIL.Image.BICUBIC)\n",
    "rotated_img\n",
    "\n",
    "\n",
    "# matches = libem.locate_numbers(\n",
    "#     phase1_results_df.query(\"frame == @base\").assign(\n",
    "#         bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "ocr = libem.get_ocr()\n",
    "ocr_df = libem.paddle_results_to_df(ocr.ocr(np.asarray(rotated_img), cls=True)[0])\n",
    "\n",
    "# sam_masks = mask_generator.generate(np.asarray(rotated_img))\n",
    "# sam_df = pd.DataFrame(sam_masks)\n",
    "\n",
    "ocr_df\n",
    "# sam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b204a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.404692Z",
     "start_time": "2023-06-09T22:56:23.404679Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_anns_df(anns, cmask=[1, 1, 1], alpha=0.8):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    anns = anns.sort_values(\"area\", ascending=False)\n",
    "\n",
    "    first_mask = anns.head(1).squeeze()\n",
    "\n",
    "    img = np.zeros_like(first_mask.segmentation).astype(np.bool_)\n",
    "    for ann in anns.itertuples():\n",
    "        # m = ann.segmentation[:, :, 0]\n",
    "        # color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        # color_mask = cmask + [alpha]\n",
    "        img |= ann.segmentation\n",
    "\n",
    "    img = ~img\n",
    "\n",
    "    return PIL.Image.fromarray(img)\n",
    "\n",
    "\n",
    "show_anns_df(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c496c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.405835Z",
     "start_time": "2023-06-09T22:56:23.405815Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbb = ocr_df.query(\"inference_text == 'CALORIES'\").bbox.squeeze()\n",
    "\n",
    "\n",
    "def convert_bbox_to_xywh(bbox):\n",
    "    # bbox format is [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "    x_coords = [coord[0] for coord in bbox]\n",
    "    y_coords = [coord[1] for coord in bbox]\n",
    "    x = min(x_coords)\n",
    "    y = min(y_coords)\n",
    "    w = max(x_coords) - x\n",
    "    h = max(y_coords) - y\n",
    "    return [x, y, w, h]\n",
    "\n",
    "\n",
    "sxy = convert_bbox_to_xywh(sbb)\n",
    "\n",
    "\n",
    "def p_overlap(bbox, ref_bbox=sxy):\n",
    "    # Unpack the bounding box coordinates\n",
    "    x1, y1, w1, h1 = bbox\n",
    "    x2, y2, w2, h2 = ref_bbox\n",
    "\n",
    "    # Calculate the (x, y)-coordinates of the intersection rectangle\n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1 + w1, x2 + w2)\n",
    "    y_bottom = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Compute the area of bbox\n",
    "    bbox_area = w1 * h1\n",
    "\n",
    "    # Compute the proportion of the intersection over bbox\n",
    "    overlap = intersection_area / float(bbox_area)\n",
    "\n",
    "    return overlap\n",
    "\n",
    "\n",
    "# _df = sam_df.assign(po=lambda f: f.bbox.apply(p_overlap)).sort_values(\n",
    "#     \"po\", ascending=False\n",
    "# )\n",
    "# _df[[\"left\", \"top\", \"width\", \"heigth\"]] = _df[\"bbox\"].apply(pd.Series)\n",
    "\n",
    "\n",
    "# _mdf = _df.query(\"po > 0.25\").query(\"area < 1500\")\n",
    "\n",
    "# _ddf = (\n",
    "#     _df.query(\"top > 350\").query(\"left > 750\").query(\"width < 100\")\n",
    "# )  # .query(\"area < 3000\")\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# plt.imshow(np.asarray(rotated_img))\n",
    "# show_anns_df(_mdf)\n",
    "# show_anns_df(_ddf, [1, 1, 0])\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a23b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.406994Z",
     "start_time": "2023-06-09T22:56:23.406984Z"
    }
   },
   "outputs": [],
   "source": [
    "_df.query(\"top > 350\").query(\"left > 750\").query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb800f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.407766Z",
     "start_time": "2023-06-09T22:56:23.407757Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_frames = glob.glob(f\"{wd}/*.png\")\n",
    "phase1_results_df = libem.ocr_frames(all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7bfac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:26:06.117185Z",
     "start_time": "2023-06-09T22:26:06.076252Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeca233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.408362Z",
     "start_time": "2023-06-09T22:56:23.408354Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ocr_df\n",
    "matches = libem.locate_numbers(\n",
    "    ocr_df.assign(bbox=lambda f: f.bbox.apply(libem.make_polygons_2d))\n",
    ")\n",
    "matches\n",
    "\n",
    "for landmark in config:\n",
    "    landmark\n",
    "\n",
    "    cfg = config[landmark]\n",
    "\n",
    "    # im = PIL.Image.open(base)\n",
    "    # base = os.path.basename(frame)\n",
    "    bbox = matches.query(\"landmark == @landmark\").landmark_bbox.squeeze()\n",
    "    # bbox\n",
    "\n",
    "    im, out = libem.ssocr_subimage(rotated_img, bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "\n",
    "    im\n",
    "    ocr.ocr(np.asarray(im), cls=True)[-1]\n",
    "\n",
    "    _df = pd.DataFrame(mask_generator.generate(np.asarray(im)))\n",
    "    _df[[\"left\", \"top\", \"width\", \"height\"]] = _df[\"bbox\"].apply(pd.Series)\n",
    "    # _df = _df.assign(max_asp=lambda f: max(f.width/f.height, f.height/f.width))\n",
    "    _df = _df.query(\"area.between(100, 2000)\").query(\"width < 100\")\n",
    "    #     .loc[\n",
    "    #         lambda f: (f.width.between(5, 15) & f.height.between(45, 55))\n",
    "    #         | (f.height.between(5, 15) & f.width.between(45, 55))\n",
    "    #     ]\n",
    "    _df\n",
    "    im_sam = show_anns_df(_df, [0, 0, 0]).convert(\"RGB\")\n",
    "    im_sam\n",
    "\n",
    "    np.asarray(im_sam).shape\n",
    "\n",
    "    ocr.ocr(np.asarray(im_sam), cls=True)\n",
    "    libem.run_ssocr(np.asarray(im_sam), *cfg[\"ssocr_conf\"])\n",
    "# im.save(f\"test-{landmark}.png\")\n",
    "# out\n",
    "# 1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e9ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.409087Z",
     "start_time": "2023-06-09T22:56:23.409078Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pics = []\n",
    "for frame in phase1_results_df.frame.unique()[:10]:\n",
    "    _df = phase1_results_df.query(\"frame == @frame\")\n",
    "    _df\n",
    "    rec = libem.crop_to_numbers(_df)\n",
    "    img = PIL.Image.open(frame)\n",
    "\n",
    "    crop_left, crop_right, crop_top, crop_bottom = (\n",
    "        rec[\"left\"],\n",
    "        rec[\"right\"],\n",
    "        rec[\"top\"],\n",
    "        rec[\"bottom\"],\n",
    "    )\n",
    "    crop_width = abs(crop_left - crop_right)\n",
    "    crop_height = abs(crop_top - crop_bottom)\n",
    "    crop_right += int(round(crop_width * 0.1))\n",
    "    crop_bottom += int(round(crop_height * 0.5))\n",
    "    cropped_img = img.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "    resize_height = int(cropped_img.height * (rec[\"resize_width\"] / cropped_img.width))\n",
    "    resized_img = cropped_img.resize(\n",
    "        (rec[\"resize_width\"], resize_height), PIL.Image.LANCZOS\n",
    "    )\n",
    "    rotated_img = resized_img.rotate(rec[\"angle\"], PIL.Image.BICUBIC)\n",
    "    rotated_img\n",
    "\n",
    "    matches = libem.locate_numbers(\n",
    "        phase1_results_df.query(\"frame == @base\").assign(\n",
    "            bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for landmark in libem.config:\n",
    "        landmark\n",
    "\n",
    "        cfg = config[landmark]\n",
    "\n",
    "        im = PIL.Image.open(base)\n",
    "        # base = os.path.basename(frame)\n",
    "        bbox = matches.query(\"landmark == @landmark\").landmark_bbox.squeeze()\n",
    "\n",
    "        im, out = libem.ssocr_subimage(im, bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "        ocr.ocr(np.asarray(im), cls=True)[-1]\n",
    "\n",
    "        im\n",
    "        #im.save(f\"test-{landmark}.png\")\n",
    "        out\n",
    "        pics.append(np.asarray(im))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf2420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.409742Z",
     "start_time": "2023-06-09T22:56:23.409734Z"
    }
   },
   "outputs": [],
   "source": [
    "np.histogram(pics[0][:, :, 0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07199e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.410388Z",
     "start_time": "2023-06-09T22:56:23.410380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def rescale_intensity(img, percentile_low=1, percentile_high=99):\n",
    "    # Compute percentiles for each channel\n",
    "    perc_low = np.percentile(img, percentile_low, axis=(0, 1))\n",
    "    perc_high = np.percentile(img, percentile_high, axis=(0, 1))\n",
    "\n",
    "    # Rescale intensities for each channel\n",
    "    img_rescaled = np.clip((img - perc_low) / (perc_high - perc_low), 0, 1)\n",
    "\n",
    "    return img_rescaled\n",
    "\n",
    "\n",
    "def weighted_grayscale_conversion(img, weights=(1, 1, 1)):\n",
    "    img_rescaled = rescale_intensity(img)\n",
    "\n",
    "    # Apply weights and sum across channels\n",
    "    grayscale_img = np.dot(img_rescaled, weights) / sum(weights)\n",
    "\n",
    "    grayscale_img = grayscale_img > 0.45\n",
    "\n",
    "    # Rescale to 0-255 and round\n",
    "    grayscale_img = np.round(grayscale_img * 255).astype(np.uint8)\n",
    "\n",
    "    return grayscale_img\n",
    "\n",
    "\n",
    "# plt.imshow(pics[0])\n",
    "\n",
    "th = weighted_grayscale_conversion(pics[3], (1, 1, 0))\n",
    "# th = weighted_grayscale_conversion(pics[3], [0.2126, 0.7152, 0.0722])\n",
    "\n",
    "# ocr.ocr(th)\n",
    "# libem.run_ssocr(th, {\"number-digits\": -1}, [])\n",
    "\n",
    "th = libem.tidy_crop_frame(th, [50, 0, th.shape[0], th.shape[1]])\n",
    "\n",
    "th\n",
    "# plt.imshow(th)\n",
    "# + pics[0][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e053c63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T22:56:23.410938Z",
     "start_time": "2023-06-09T22:56:23.410930Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "\n",
    "fig, ax = try_all_threshold(th)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2528fdc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(pics[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Otsu's thresholding\n",
    "thim, thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "plt.imshow(th)\n",
    "\n",
    "thim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07e17f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.489Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(pics[0][:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5c103",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.490Z"
    }
   },
   "outputs": [],
   "source": [
    "pixels = np.concatenate([e[:, :, 0].reshape(-1, 1) for e in pics])\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "print(\"Building k-means model\")\n",
    "# Train K-means model\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703e0fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.490Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p in pics[:12]:\n",
    "    labels = kmeans.predict(p[:, :, 0].reshape(-1, 1))\n",
    "    if (labels == 0).mean() > 0.5:\n",
    "        label = 1 - labels\n",
    "    p_seg = (labels.reshape(p.shape[:2]) * 255).astype(np.uint8)\n",
    "    PIL.Image.fromarray(p_seg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21646f0e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.491Z"
    }
   },
   "outputs": [],
   "source": [
    "libem.crop_to_numbers(_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc31104",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.491Z"
    }
   },
   "outputs": [],
   "source": [
    "ocr = libem.get_ocr()\n",
    "ocr.ocr(np.asarray(im), cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8098",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.491Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base = \"/tmp/tmph7n2du9x/output_040.png\"\n",
    "\n",
    "\n",
    "matches = libem.locate_numbers(\n",
    "    phase1_results_df.query(\"frame == @base\").assign(\n",
    "        bbox=lambda f: f.bbox.apply(libem.make_polygons_2d)\n",
    "    )\n",
    ")\n",
    "matches\n",
    "for landmark in libem.config:\n",
    "    landmark\n",
    "\n",
    "    cfg = libem.config[landmark]\n",
    "\n",
    "    im = PIL.Image.open(base)\n",
    "    # base = os.path.basename(frame)\n",
    "    bbox = matches.query(\"landmark == @landmark\").landmark_bbox.squeeze()\n",
    "\n",
    "    im, out = libem.ssocr_subimage(im, bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "    ocr.ocr(np.asarray(im), cls=True)[-1]\n",
    "\n",
    "    im\n",
    "    im.save(f\"test-{landmark}.png\")\n",
    "    out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6646e5d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.491Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56add332",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.492Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_distance(series):\n",
    "    return (\n",
    "        series\n",
    "        # Replace non-matching strings with ''\n",
    "        .where(series.str.match(\"\\d\\.\\d{2}$\", na=False), \"\")\n",
    "        # Convert the strings to float, invalid parsing will be set as NaN\n",
    "        .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        # Set type\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "\n",
    "def process_calories(series):\n",
    "    return (\n",
    "        series\n",
    "        # Create a copy of the series to preserve the original one\n",
    "        # .copy()\n",
    "        # Replace non-digit characters with ''\n",
    "        .str.replace(\"[^\\d]\", \"\", regex=True)\n",
    "        # Convert the strings to integers, invalid parsing will be set as NaN\n",
    "        .pipe(pd.to_numeric, errors=\"coerce\", downcast=\"integer\").astype(float)\n",
    "        # Convert NaN values to pd.NA to have a nullable integer series\n",
    "        # .replace(np.nan, pd.NA)\n",
    "    )\n",
    "\n",
    "\n",
    "# plt.plot(pp.DISTANCE.pipe(process_distance), ss.DISTANCE.pipe(process_distance))\n",
    "plt.plot(pp.DISTANCE.pipe(process_distance))\n",
    "plt.plot(ss.DISTANCE.pipe(process_distance))\n",
    "# plt.plot(pp, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c993f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.493Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(ss.CALORIES.pipe(process_calories))\n",
    "plt.plot(pp.CALORIES.pipe(process_calories))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8732c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.493Z"
    }
   },
   "outputs": [],
   "source": [
    "Flow(\"BuildMonitorDatasetFlow\").latest_successful_run.data.ocr_df.query(\n",
    "    \"marker == 'TIME'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c16fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.494Z"
    }
   },
   "outputs": [],
   "source": [
    "df = Flow(\n",
    "    \"BuildMonitorDatasetFlow\"\n",
    ").latest_successful_run.data.phase_1_detection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ac077",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.495Z"
    }
   },
   "outputs": [],
   "source": [
    "f45 = df.query(\"frame.str.contains('045')\")\n",
    "f45.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4909641",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.495Z"
    }
   },
   "outputs": [],
   "source": [
    "wd = tempfile.mkdtemp()\n",
    "args = [\n",
    "            '/bucket/exercise-machina/IMG_1392.MOV',\n",
    "            wd,\n",
    "            \"3:30\",\n",
    "\"10\",\"output_%03d.png\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "libem.unpack_video_to_frames(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601877b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.496Z"
    }
   },
   "outputs": [],
   "source": [
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=True, lang=\"en\"\n",
    ")  # need to run only once to download and load model into memory\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "im = Image.open(\"/bucket/exercise-machina/tmpqdhq4d5e/frames/output_1404.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349a33c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.496Z"
    }
   },
   "outputs": [],
   "source": [
    "def paddle_results_to_df(result):\n",
    "    df = pd.DataFrame(result, columns=[\"bbox\", \"inference\"])\n",
    "    df[[\"inference_text\", \"inference_score\"]] = pd.DataFrame(\n",
    "        df[\"inference\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    df.drop(columns=\"inference\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def crop_image(image, bbox):\n",
    "    \"\"\"\n",
    "    Crop an image (in numpy representation) to the given bounding box.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The input image in numpy format (height, width, channels)\n",
    "    - bbox (list or tuple): The bounding box as (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    Returns:\n",
    "    - cropped_image (numpy.ndarray): The cropped image\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def make_polygons_2d(polygons):\n",
    "    return np.concatenate(polygons).reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "\n",
    "def super_bounding_box(xy):\n",
    "    xx, yy = xy[:, 0], xy[:, 1]\n",
    "\n",
    "    return [xx.min(), xx.max(), yy.min(), yy.max()]\n",
    "\n",
    "\n",
    "def best_match_2(text, markers):\n",
    "    # calculate the best match out of the possible markers\n",
    "    best = process.extractOne(text, markers, score_cutoff=90)\n",
    "    if best is None:\n",
    "        return \"\"\n",
    "    return best[0]\n",
    "\n",
    "\n",
    "def compute_distance(bbox1, bbox2):\n",
    "    center1 = bbox1.mean(axis=0)\n",
    "    try:\n",
    "        # Compute centers of mass\n",
    "        center1 = bbox1.mean(axis=0)\n",
    "        center2 = bbox2.mean(axis=0)\n",
    "\n",
    "        # Compute Euclidean distance between centers\n",
    "        distance = np.linalg.norm(center1 - center2)\n",
    "    except:\n",
    "        return 1000\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def compute_angle(bbox1, bbox2):\n",
    "    try:\n",
    "        # Compute centers of mass\n",
    "        center1 = bbox1.mean(axis=0)\n",
    "        center2 = bbox2.mean(axis=0)\n",
    "\n",
    "        # Compute angle relative to bbox1\n",
    "        diff = center2 - center1\n",
    "        angle = math.atan2(diff[1], diff[0]) * 180 / math.pi\n",
    "    except:\n",
    "        return 180\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def process_group_2(group):\n",
    "    landmarks = group.assign(\n",
    "        inference_clean=group[\"inference_text\"].apply(best_match_2)\n",
    "    )\n",
    "\n",
    "    uniques = [\"SPEED\", \"WATTS\", \"CADENCE\", \"CALORIES\"]\n",
    "    surround_box = super_bounding_box(\n",
    "        make_polygons_2d(\n",
    "            landmarks.query(\"inference_clean.isin(@uniques)\").bbox.to_numpy()\n",
    "        )\n",
    "    )\n",
    "    xl, xr, yt, yb = surround_box\n",
    "    w = abs(xl - xr)\n",
    "    h = abs(yt - yb)\n",
    "    print(w, h)\n",
    "    # surround_box = [xl, yt, round(xr + 1.05 * w), round(yb - h)]\n",
    "    return (round(xl - 0.02 * w), yt, round(xr + 0.075 * w), round(yb + 0.42 * h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf1217",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.497Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plausible_number(w, thresh=0.5):\n",
    "    return (sum(1 for c in w if c.isdigit() or c in \":.\") / len(w)) > thresh\n",
    "\n",
    "\n",
    "def locate_numbers(\n",
    "    df,\n",
    "    landmarks=(\n",
    "        \"SPEED\",\n",
    "        \"WATTS\",\n",
    "        \"CADENCE\",\n",
    "        \"CALORIES\",\n",
    "        \"DISTANCE\",\n",
    "        \"TIME\",\n",
    "    ),\n",
    "    min_score=0.9,\n",
    "):\n",
    "    candidates_df = (\n",
    "        df.query(\"inference_score >= @min_score\")\n",
    "        .loc[lambda f: f.inference_text.apply(plausible_number)]\n",
    "        .reset_index(drop=True)\n",
    "        .assign(box_id=lambda f: range(len(f)))\n",
    "    )\n",
    "\n",
    "    out = []\n",
    "    for landmark in landmarks:\n",
    "        rec = df.query(\"inference_text == @landmark\")\n",
    "        if landmark == \"TIME\":\n",
    "            # TIME matches two places typically, we want the one more to the left.\n",
    "            rec = (\n",
    "                rec.assign(\n",
    "                    bbox_left=lambda f: [e[:, 0].min() for e in f.bbox]\n",
    "                ).sort_values(\"bbox_left\")\n",
    "            ).head(1)\n",
    "        assert len(rec) == 1\n",
    "        rec = rec.squeeze()\n",
    "\n",
    "        _df = (\n",
    "            candidates_df.assign(\n",
    "                distance_from_ref=lambda f: [\n",
    "                    compute_distance(rec.bbox, e) for e in f.bbox\n",
    "                ],\n",
    "                angle_from_ref=lambda f: [compute_angle(rec.bbox, e) for e in f.bbox],\n",
    "            )\n",
    "            .assign(\n",
    "                belowness_score=lambda f: f.distance_from_ref\n",
    "                + abs(f.angle_from_ref - 90)\n",
    "            )\n",
    "            .sort_values(\"belowness_score\")\n",
    "        )\n",
    "\n",
    "        out.append(_df.head(1).assign(landmark=landmark, landmark_bbox=[rec.bbox]))\n",
    "\n",
    "    return (\n",
    "        pd.concat(out)\n",
    "        .sort_values([\"box_id\", \"belowness_score\"])\n",
    "        .assign(\n",
    "            inference_text=lambda f: f.inference_text.where(\n",
    "                ~f.duplicated(subset=\"box_id\"), None\n",
    "            ),\n",
    "            inference_score=lambda f: f.inference_score.where(\n",
    "                f.inference_text.notnull(), None\n",
    "            ),\n",
    "            bbox=lambda f: f.bbox.where(f.inference_text.notnull(), None),\n",
    "        )\n",
    "        .loc[\n",
    "            :,\n",
    "            [\n",
    "                \"landmark\",\n",
    "                \"inference_text\",\n",
    "                \"inference_score\",\n",
    "                # \"distance_from_ref\",\n",
    "                # \"angle_from_ref\",\n",
    "                # \"belowness_score\",\n",
    "                # \"box_id\",\n",
    "                \"landmark_bbox\",\n",
    "                \"bbox\",\n",
    "            ],\n",
    "        ]\n",
    "        .rename(columns={\"bbox\": \"match_bbox\"})\n",
    "        .sort_values(\"landmark\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "# ff = paddle_results_to_df(ocr.ocr(np.asarray(im), cls=True)[0])\n",
    "# ff\n",
    "\n",
    "\n",
    "bb = locate_numbers(ff.assign(bbox=lambda f: f.bbox.apply(make_polygons_2d)))\n",
    "bb\n",
    "\n",
    "\n",
    "# imc = im.crop(bb)\n",
    "\n",
    "# resize_width = 1000\n",
    "# resize_height = int(\n",
    "#     imc.height * (resize_width / imc.width)\n",
    "# )\n",
    "# imd = imc.resize(\n",
    "#     (resize_width, resize_height), Image.LANCZOS\n",
    "# )\n",
    "# imd\n",
    "\n",
    "# paddle_results_to_df(ocr.ocr(np.asarray(imd), cls=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea4ddb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.498Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"SPEED\": dict(\n",
    "        sel=(-0.2, 1.25, 1.03, 2.7),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"WATTS\": dict(\n",
    "        sel=(-0.2, 1.1, 0.6, 2.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CADENCE\": dict(\n",
    "        sel=(0, 1.25, 0.20, 2.9),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"DISTANCE\": dict(\n",
    "        sel=(0, 1.3, 0.75, 3.25),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"TIME\": dict(\n",
    "        sel=(-1.2, 1.2, 1.45, 2.75),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CALORIES\": dict(\n",
    "        sel=(0, 1.2, 0.2, 2.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "sample = (\n",
    "    pd.Series(glob.glob(\"/bucket/exercise-machina/tmpqdhq4d5e/frames/*.png\"))\n",
    "    .sample(5, random_state=2009, replace=False)\n",
    "    .sort_values()\n",
    "    .tolist()\n",
    ")\n",
    "sample = sorted(glob.glob(\"/bucket/exercise-machina/tmpqdhq4d5e/frames/output_1*.png\"))\n",
    "\n",
    "match_frames = []\n",
    "for e in sample:\n",
    "    im = Image.open(e)\n",
    "    ocr_df = paddle_results_to_df(ocr.ocr(np.asarray(im), cls=True)[0]).assign(\n",
    "        bbox=lambda f: f.bbox.apply(make_polygons_2d)\n",
    "    )\n",
    "    order = int(\"\".join([c for c in os.path.basename(e) if c.isdigit()]))\n",
    "    match_frame = locate_numbers(ocr_df).assign(frame=e, frame_num=order)\n",
    "\n",
    "    ssocr_inf = []\n",
    "    for rec in match_frame.itertuples():\n",
    "        cfg = config[rec.landmark]\n",
    "        imc, out = ssocr_subimage(im.convert(\"L\"), rec.landmark_bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "        ssocr_inf.append(out)\n",
    "    match_frame = match_frame.assign(ssocr=ssocr_inf)\n",
    "\n",
    "    match_frames.append(match_frame)\n",
    "\n",
    "matches = pd.concat(match_frames).sort_values([\"frame_num\", \"landmark\"])\n",
    "matches.to_csv(\"ocr-output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934c318",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.498Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matches.assign(assigned=lambda f: f.inference_text.notnull()).groupby(\n",
    "    \"landmark\"\n",
    ").assigned.mean().sort_values().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3766e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.499Z"
    }
   },
   "outputs": [],
   "source": [
    "matches.head()\n",
    "\n",
    "(matches.inference_text == matches.ssocr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab0d61",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.499Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_crop(a, cf):\n",
    "    l, t, r, b = cf\n",
    "    perimeter = np.concatenate(\n",
    "        [\n",
    "            a[t:b, l].flatten(),\n",
    "            a[t:b, r].flatten(),\n",
    "            a[t, l:r].flatten(),\n",
    "            a[t, l:r].flatten(),\n",
    "        ]\n",
    "    )\n",
    "    score = perimeter.mean() + perimeter.std()\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def tidy_crop_frame(a, cf, w=15):\n",
    "    best_score = score_crop(a, cf)\n",
    "    best_crop = cf\n",
    "\n",
    "    # print(f\"{cf=}\")\n",
    "    for ix in range(len(cf)):\n",
    "        dr = 1 if (ix >= 2) else -1\n",
    "        for d in range(-w * dr, w * dr):\n",
    "            cfp = cf.copy()\n",
    "            cfp[ix] += d\n",
    "            score = score_crop(a, cfp)\n",
    "            if score < best_score:\n",
    "                # print(f\"{best_score=} {ix=} {d=} {cfp=}\")\n",
    "                best_score = score\n",
    "                best_crop = cfp\n",
    "\n",
    "    return best_crop\n",
    "\n",
    "\n",
    "def ssocr_subimage(im, bbox, selection, ssocr_config):\n",
    "    xy = make_polygons_2d(bbox)\n",
    "\n",
    "    l, t, r, b = (xy[:, 0].min(), xy[:, 1].min(), xy[:, 0].max(), xy[:, 1].max())\n",
    "    w = abs(l - r)\n",
    "    h = abs(t - b)\n",
    "\n",
    "    s = selection\n",
    "    init_crop_frame = [\n",
    "        int(round(e))\n",
    "        for e in (\n",
    "            l + s[0] * w,\n",
    "            t + s[1] * h,\n",
    "            r + s[2] * w,\n",
    "            b + s[3] * h,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    crop_frame = tidy_crop_frame(np.asarray(im), init_crop_frame)\n",
    "    imc = im.crop(crop_frame)\n",
    "\n",
    "    return imc, run_ssocr(np.asarray(imc), *ssocr_config)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"SPEED\": dict(\n",
    "        sel=(-0.2, 1.25, 1.03, 2.7),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"WATTS\": dict(\n",
    "        sel=(-0.2, 1.1, 0.6, 2.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CADENCE\": dict(\n",
    "        sel=(0, 1.25, 0.20, 2.9),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"DISTANCE\": dict(\n",
    "        sel=(0, 1.3, 0.75, 3.25),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"TIME\": dict(\n",
    "        sel=(-1.2, 1.2, 1.45, 2.75),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "    \"CALORIES\": dict(\n",
    "        sel=(0, 1.2, 0.2, 2.5),\n",
    "        ssocr_conf=(\n",
    "            {\"number-digits\": -1, \"threshold\": 40},\n",
    "            [],\n",
    "        ),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "landmark = \"CALORIES\"\n",
    "for frame in sample:\n",
    "    cfg = config[landmark]\n",
    "\n",
    "    im = images[sample.index(frame)]\n",
    "    base = os.path.basename(frame)\n",
    "    bbox = (\n",
    "        matches.query(\"frame == @base\")\n",
    "        .query(\"landmark == @landmark\")\n",
    "        .landmark_bbox.squeeze()\n",
    "    )\n",
    "\n",
    "    im, out = ssocr_subimage(im, bbox, cfg[\"sel\"], cfg[\"ssocr_conf\"])\n",
    "\n",
    "    im\n",
    "    out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce5ca4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.500Z"
    }
   },
   "outputs": [],
   "source": [
    "bbox.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7491918",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.500Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import cv2\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "def run_ssocr(image, params, commands):\n",
    "    # Define the command and parameters\n",
    "    cmd = [\"./ssocr-2.22.2/ssocr\"]\n",
    "\n",
    "    # Add the parameters to the command\n",
    "    for key, value in params.items():\n",
    "        if value is None:\n",
    "            cmd.append(f\"--{key}\")\n",
    "        else:\n",
    "            cmd.append(f\"--{key}={value}\")\n",
    "\n",
    "    for _cmd in commands:\n",
    "        cmd.extend(_cmd.split())\n",
    "\n",
    "    # If the input is a numpy array, write it to a temporary file\n",
    "    if isinstance(image, str):\n",
    "        cmd.append(image)\n",
    "    else:\n",
    "        # Create a temporary file\n",
    "        temp_file = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "        temp_file_path = temp_file.name\n",
    "        # Write the image to the temporary file\n",
    "        cv2.imwrite(temp_file_path, image)\n",
    "        cmd.append(temp_file_path)\n",
    "\n",
    "    # print(f\"{cmd=}\")\n",
    "\n",
    "    # Run the command and get the output\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    # Delete the temporary file if it was used\n",
    "    if not isinstance(image, str):\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "    # Check for errors\n",
    "    if result.stderr:\n",
    "        print(f\"Error: {result.stderr.decode()}\")\n",
    "\n",
    "    # Return the output\n",
    "    return result.stdout.decode().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9924c2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.501Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal as ss\n",
    "\n",
    "i = 1\n",
    "a.std(i).shape\n",
    "pd.Series(-a.std(i)).plot()\n",
    "# plt.imshow(ima[:, :, 1])\n",
    "# plt.imshow(ima[:, :, 2])\n",
    "\n",
    "ss.find_peaks(-a.std(i), prominence=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53ea18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.501Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Building up some pixels for clustering\")\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "# Build k-means model to threshold images.\n",
    "pixels = np.asarray(imc)\n",
    "pixels.shape\n",
    "_pixels = pixels.reshape(-1, 3)\n",
    "\n",
    "print(\"Building k-means model\")\n",
    "# Train K-means model\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=4)\n",
    "kmeans.fit(_pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2afa6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.502Z"
    }
   },
   "outputs": [],
   "source": [
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb55004",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.503Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imb = kmeans.predict(_pixels).reshape(422, 843) == 3\n",
    "imb.shape\n",
    "#plt.imshow(imb)\n",
    "imbb = np.zeros_like(pixels)\n",
    "# imbb\n",
    "imbb[:, :, 0] = imb * 255\n",
    "imbb[:, :, 1] = imb * 255\n",
    "imbb[:, :, 2] = imb * 255\n",
    "imbb = Image.fromarray(imbb)\n",
    "\n",
    "imbb.height, imbb.width\n",
    "\n",
    "resize_width = 1000\n",
    "resize_height = int(\n",
    "    imbb.height * (resize_width / imbb.width)\n",
    ")\n",
    "resized_img = imbb.resize(\n",
    "    (resize_width, resize_height), Image.LANCZOS\n",
    ")\n",
    "\n",
    "resized_img\n",
    "\n",
    "\n",
    "paddle_results_to_df(ocr.ocr(np.asarray(resized_img), cls=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a26e5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.503Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list(Run(\"BuildMonitorDatasetFlow/24\").steps())\n",
    "\n",
    "Step(\"BuildMonitorDatasetFlow/24/text_detect_phase2\").phase_2_detection_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f1894",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.504Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ocr_df.loc[:, [\"speed\", \"watts\", \"cadence\"]]\n",
    "\n",
    "ocr_df.speed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f009de",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.504Z"
    }
   },
   "outputs": [],
   "source": [
    "trdf = pd.read_csv(\"./top-row-states.csv\")\n",
    "\n",
    "p9.ggplot(trdf, p9.aes(\"cadence\", \"speed\")) + p9.geom_line() + p9.geom_point()\n",
    "\n",
    "p9.ggplot(trdf, p9.aes(\"cadence\", \"watts\")) + p9.geom_line() + p9.geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69dac5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.505Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ocr_df.loc[:, [\"time\", \"distance\", \"calories\"]].to_csv(\"moo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a339aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T00:44:57.337793Z",
     "start_time": "2023-05-08T00:44:57.310352Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4d2af",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.506Z"
    }
   },
   "outputs": [],
   "source": [
    "lnl = sum(\n",
    "    np.log(\n",
    "        1e-3\n",
    "        + rapidfuzz.process.cdist(\n",
    "            ocr_df[term],\n",
    "            trdf[term].astype(\"str\"),\n",
    "            processor=lambda w: \"\".join(e for e in w if e.isdigit()),\n",
    "        )\n",
    "    )\n",
    "    for term in (\"speed\", \"watts\", \"cadence\")\n",
    ")\n",
    "n = 11\n",
    "pd.concat(\n",
    "    [\n",
    "        ocr_df.reset_index(drop=True),\n",
    "        trdf.loc[lnl.argmax(axis=1)].reset_index(drop=True),\n",
    "    ],\n",
    "    axis=\"columns\",\n",
    "    ignore_index=True,\n",
    ").to_csv(\"ocr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59769abe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.507Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.json_normalize(\n",
    "    Flow(\"BuildMonitorDatasetFlow\").latest_successful_run.data.phase1_results[\n",
    "        \"predictions\"\n",
    "    ]\n",
    ").loc[:, [\"rec_texts\", \"det_polygons\"]].explode([\"rec_texts\", \"det_polygons\"]).query(\n",
    "    \"rec_texts in ('speed', 'cadence', 'distance', 'calories')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add21519",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.507Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mmocr.apis import MMOCRInferencer\n",
    "\n",
    "ocr = MMOCRInferencer(det=\"DBNetpp\", rec=\"ABINet\")\n",
    "\n",
    "ocr(\"/bucket/exercise-machina/frames\",\n",
    "    batch_size=8,\n",
    "    out_dir=\"/bucket/exercise-machina/frames-ocr\",\n",
    "   save_pred=True\n",
    "   )\n",
    "\n",
    "#x = ocr(\"output_001.png\", show=False, print_result=False, return_vis=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1cd21",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.508Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "def display_image(image, width_inches=12.5):\n",
    "    height, width, _ = image.shape\n",
    "    aspect_ratio = height / width\n",
    "\n",
    "    fig_width = width_inches\n",
    "    fig_height = width_inches * aspect_ratio\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_ocr_results(image, ocr_data, extra_polygons=[]):\n",
    "    # Convert the image to BGR format for drawing with OpenCV\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for ix, row in ocr_data.iterrows():\n",
    "        text = row[\"rec_texts\"]\n",
    "        polygon = row[\"det_polygons\"]\n",
    "        points = np.array(polygon).reshape(-1, 2).astype(np.int32)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.polylines(image, [points], isClosed=True, color=(0, 255, 255), thickness=2)\n",
    "\n",
    "        # Calculate the center of the bounding box\n",
    "        center = points.mean(axis=0).astype(np.int32)\n",
    "\n",
    "        # Put the text annotation in the center of the bounding box\n",
    "        cv2.putText(\n",
    "            image, text, tuple(center), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2\n",
    "        )\n",
    "\n",
    "    for pg in extra_polygons:\n",
    "        points = np.array(pg).reshape(-1, 2).astype(np.int32)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.polylines(image, [points], isClosed=True, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def find_most_similar_text(df, query, similarity_threshold=90):\n",
    "    best_match = None\n",
    "    best_similarity = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        similarity = fuzz.ratio(query, row[\"rec_texts\"])\n",
    "        if (similarity >= similarity_threshold) and (similarity > best_similarity):\n",
    "            best_similarity = similarity\n",
    "            best_match = row\n",
    "\n",
    "    if best_match is not None:\n",
    "        return np.asarray(best_match[\"det_polygons\"]).reshape(-1, 2).astype(np.int32)\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "def super_bounding_box(landmarks, keys):\n",
    "    min_x, min_y = float(\"inf\"), float(\"inf\")\n",
    "    max_x, max_y = float(\"-inf\"), float(\"-inf\")\n",
    "\n",
    "    for key in keys:\n",
    "        if key not in landmarks:\n",
    "            raise ValueError(f\"Key '{key}' not found in landmarks.\")\n",
    "\n",
    "        bounding_box = landmarks[key]\n",
    "        x1, y1 = bounding_box[:, 0].min(), bounding_box[:, 1].min()\n",
    "        x2, y2 = bounding_box[:, 0].max(), bounding_box[:, 1].max()\n",
    "\n",
    "        min_x, min_y = min(min_x, x1), min(min_y, y1)\n",
    "        max_x, max_y = max(max_x, x2), max(max_y, y2)\n",
    "\n",
    "    return np.array([[min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y]])\n",
    "\n",
    "\n",
    "def infill_bounding_box(landmarks, key1, key2):\n",
    "    if key1 not in landmarks:\n",
    "        raise ValueError(f\"Key '{key1}' not found in landmarks.\")\n",
    "    if key2 not in landmarks:\n",
    "        raise ValueError(f\"Key '{key2}' not found in landmarks.\")\n",
    "\n",
    "    bbox1 = landmarks[key1]\n",
    "    bbox2 = landmarks[key2]\n",
    "\n",
    "    x1_1, y1_1 = bbox1[:, 0].min(), bbox1[:, 1].min()\n",
    "    x1_2, y1_2 = bbox1[:, 0].max(), bbox1[:, 1].max()\n",
    "\n",
    "    x2_1, y2_1 = bbox2[:, 0].min(), bbox2[:, 1].min()\n",
    "    x2_2, y2_2 = bbox2[:, 0].max(), bbox2[:, 1].max()\n",
    "\n",
    "    min_x = max(x1_2, x2_1)\n",
    "    max_x = min(x1_1, x2_2)\n",
    "    min_y = max(y1_1, y2_1)\n",
    "    max_y = min(y1_2, y2_2)\n",
    "\n",
    "    return np.array([[min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y]])\n",
    "\n",
    "\n",
    "def infill_top_bottom_bbox(landmarks, top_key, bottom_key):\n",
    "    if top_key not in landmarks:\n",
    "        raise ValueError(f\"Key '{top_key}' not found in landmarks.\")\n",
    "    if bottom_key not in landmarks:\n",
    "        raise ValueError(f\"Key '{bottom_key}' not found in landmarks.\")\n",
    "\n",
    "    top_bbox = landmarks[top_key]\n",
    "    bottom_bbox = landmarks[bottom_key]\n",
    "\n",
    "    top_left = [top_bbox[:, 0].min(), top_bbox[:, 1].max()]\n",
    "    top_right = [top_bbox[:, 0].max(), top_bbox[:, 1].max()]\n",
    "\n",
    "    bottom_left = [bottom_bbox[:, 0].min(), bottom_bbox[:, 1].min()]\n",
    "    bottom_right = [bottom_bbox[:, 0].max(), bottom_bbox[:, 1].min()]\n",
    "\n",
    "    return np.array([top_left, top_right, bottom_right, bottom_left])\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# landmarks = {\n",
    "#     'top_key': np.array([[10, 20], [30, 20], [30, 40], [10, 40]]),\n",
    "#     'bottom_key': np.array([[15, 50], [25, 50], [25, 60], [15, 60]]),\n",
    "# }\n",
    "# infill_top_bottom = infill_top_bottom_bbox(landmarks, 'top_key', 'bottom_key')\n",
    "# print(infill_top_bottom)\n",
    "\n",
    "\n",
    "def build_ss_polygons(df):\n",
    "    landmarks = [\n",
    "        \"rogue\",\n",
    "        \"intervals\",\n",
    "        \"speed\",\n",
    "        \"mph\",\n",
    "        \"watts\",\n",
    "        \"cadence\",\n",
    "        \"targets\",\n",
    "        \"distance\",\n",
    "        \"time\",\n",
    "        \"calories\",\n",
    "        \"heart\",\n",
    "        \"rate\",\n",
    "        \"intervals\",\n",
    "    ]\n",
    "    landmark_map = dict((e, find_most_similar_text(df, e)) for e in landmarks)\n",
    "\n",
    "    landmark_map[\"smwc\"] = super_bounding_box(\n",
    "        landmark_map, [\"speed\", \"mph\", \"watts\", \"cadence\"]\n",
    "    )\n",
    "    landmark_map[\"tdtc\"] = super_bounding_box(\n",
    "        landmark_map, [\"targets\", \"distance\", \"time\", \"calories\"]\n",
    "    )\n",
    "    landmark_map[\"hr\"] = super_bounding_box(landmark_map, [\"heart\", \"rate\"])\n",
    "\n",
    "    #     landmark_map[\"upper_row\"] = infill_top_bottom_bbox(\n",
    "    #         landmark_map, \"speed+mph\", \"tdtc\"\n",
    "    #     )\n",
    "    #     landmark_map[\"lower_row\"] = infill_top_bottom_bbox(landmark_map, \"tdtc\", \"hr\")\n",
    "\n",
    "    return landmark_map\n",
    "\n",
    "\n",
    "#     return [\n",
    "#         landmark_map[\"upper_row\"],\n",
    "#         landmark_map[\"lower_row\"],\n",
    "#     ]\n",
    "\n",
    "\n",
    "ocr_df = pd.DataFrame(x[\"predictions\"][0])\n",
    "\n",
    "image = cv2.imread(\"output_001.png\")\n",
    "\n",
    "\n",
    "digit_bboxes = build_ss_polygons(ocr_df)\n",
    "\n",
    "image_p = draw_ocr_results(image, ocr_df, [])\n",
    "\n",
    "display_image(image_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a912a0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.509Z"
    }
   },
   "outputs": [],
   "source": [
    "display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36d3f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.509Z"
    }
   },
   "outputs": [],
   "source": [
    "# digit_bboxes\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "keys = (\n",
    "    [\"rogue\", \"intervals\"]\n",
    "    + [\"speed\", \"mph\", \"watts\", \"cadence\"]\n",
    "    + [\"targets\", \"distance\", \"time\", \"calories\"]\n",
    "    + [\"heart\", \"rate\"]\n",
    ")\n",
    "\n",
    "for key in keys:\n",
    "    slope, *rest = linregress(digit_bboxes[key][:, 0], digit_bboxes[key][:, 1])\n",
    "    angle_rad = np.arctan(slope)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    key, slope, angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d28c97",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.510Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def estimate_angle_from_horizontal(bbox):\n",
    "    # Get the x and y coordinates of the bounding box corners\n",
    "    x = bbox[:, 0].reshape(-1, 1)\n",
    "    y = bbox[:, 1]\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "\n",
    "    # Calculate the angle from the slope using arctan\n",
    "    angle_rad = np.arctan(lr.coef_[0])\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    # Adjust the angle to be within -90 to 90 degrees\n",
    "    if angle_deg > 45:\n",
    "        angle_deg -= 90\n",
    "    elif angle_deg < -45:\n",
    "        angle_deg += 90\n",
    "\n",
    "    return angle_deg\n",
    "\n",
    "# Example usage:\n",
    "# bbox = np.array([[10, 20], [30, 20], [30, 40], [10, 40]])\n",
    "# angle = estimate_angle_from_horizontal(bbox)\n",
    "# print(angle)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def optimal_rectangular_transform(bboxes):\n",
    "    transforms = []\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        # Estimate angles for each pair of opposite sides\n",
    "        angle1 = estimate_angle_from_horizontal(bbox[[0, 1], :])\n",
    "        angle2 = estimate_angle_from_horizontal(bbox[[2, 3], :])\n",
    "        angle3 = estimate_angle_from_horizontal(bbox[[0, 3], :])\n",
    "        angle4 = estimate_angle_from_horizontal(bbox[[1, 2], :])\n",
    "\n",
    "        # Average the angles\n",
    "        avg_horizontal_angle = (angle1 + angle2) / 2\n",
    "        avg_vertical_angle = (angle3 + angle4) / 2\n",
    "\n",
    "        # Get the center of the bounding box\n",
    "        center = np.mean(bbox, axis=0)\n",
    "\n",
    "        # Calculate the affine transformation matrix\n",
    "        horizontal_rotation_matrix = cv2.getRotationMatrix2D(tuple(center), avg_horizontal_angle, 1)\n",
    "        vertical_rotation_matrix = cv2.getRotationMatrix2D(tuple(center), avg_vertical_angle, 1)\n",
    "\n",
    "        # Apply the horizontal rotation\n",
    "        rotated_bbox = cv2.transform(np.float32([bbox]), horizontal_rotation_matrix)[0]\n",
    "\n",
    "        # Compute the vertical rotation center\n",
    "        rotated_center = np.mean(rotated_bbox, axis=0)\n",
    "\n",
    "        # Calculate the vertical rotation matrix based on the rotated center\n",
    "        vertical_rotation_matrix = cv2.getRotationMatrix2D(tuple(rotated_center), avg_vertical_angle, 1)\n",
    "\n",
    "        # Store the transformation matrices\n",
    "        transforms.append((horizontal_rotation_matrix, vertical_rotation_matrix))\n",
    "\n",
    "    return transforms\n",
    "\n",
    "# Example usage:\n",
    "# bboxes = [np.array([[10, 20], [30, 20], [30, 40], [10, 40]])]\n",
    "# transforms = optimal_rectangular_transform(bboxes)\n",
    "# print(transforms)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "bboxes = [digit_bboxes[\"rogue\"], digit_bboxes[\"cadence\"]]\n",
    "transforms = optimal_rectangular_transform(bboxes)\n",
    "print(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba418a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.510Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def compute_perspective_transform(bbox, target_bbox):\n",
    "    src_points = np.float32(bbox)\n",
    "    dst_points = np.float32(target_bbox)\n",
    "    transformation_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    return transformation_matrix\n",
    "\n",
    "bboxes = [...]  # List of k bounding boxes\n",
    "target_bboxes = [...]  # List of k corresponding target rectangular bounding boxes\n",
    "weights = [...]  # List of k corresponding weights\n",
    "\n",
    "# Calculate the perspective transformations for each bounding box\n",
    "transformations = [compute_perspective_transform(bbox, target_bbox)\n",
    "                   for bbox, target_bbox in zip(bboxes, target_bboxes)]\n",
    "\n",
    "# Normalize the weights\n",
    "normalized_weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "# Compute the weighted average of the transformation matrices\n",
    "weighted_avg_transform = np.zeros((3, 3), dtype=np.float32)\n",
    "for transform, weight in zip(transformations, normalized_weights):\n",
    "    weighted_avg_transform += transform * weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3fa6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.511Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def display_image(img):\n",
    "    _, img_encoded = cv2.imencode('.png', img)\n",
    "    img_bytes = img_encoded.tobytes()\n",
    "    img_pil = Image.open(BytesIO(img_bytes))\n",
    "    display(img_pil)\n",
    "\n",
    "def warp_perspective(angle, scale, tx, ty):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    rows, cols, _ = img.shape\n",
    "    center = (cols // 2, rows // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotation_matrix[:, 2] += [tx, ty]\n",
    "\n",
    "    img_warped = cv2.warpAffine(img, rotation_matrix, (cols, rows))\n",
    "    display_image(img_warped)\n",
    "\n",
    "# Load your input image\n",
    "#img = cv2.imread('path/to/your/image.jpg')\n",
    "img = image_p\n",
    "\n",
    "# Create widgets for the transformation parameters\n",
    "angle_slider = widgets.FloatSlider(min=-5, max=5, step=0.1, value=0, description='Rotation Angle')\n",
    "scale_slider = widgets.FloatSlider(min=0.1, max=3, step=0.1, value=1, description='Scale')\n",
    "tx_slider = widgets.IntSlider(min=-100, max=100, step=1, value=0, description='Translation X')\n",
    "ty_slider = widgets.IntSlider(min=-100, max=100, step=1, value=0, description='Translation Y')\n",
    "\n",
    "widgets.interact(warp_perspective, angle=angle_slider, scale=scale_slider, tx=tx_slider, ty=ty_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e3103",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.511Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def display_image(img):\n",
    "    _, img_encoded = cv2.imencode('.png', img)\n",
    "    img_bytes = img_encoded.tobytes()\n",
    "    img_pil = Image.open(BytesIO(img_bytes))\n",
    "    display(img_pil)\n",
    "\n",
    "\n",
    "def warp_perspective(pitch, yaw, roll):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    def rotation_matrix(axis, angle):\n",
    "        return cv2.Rodrigues(np.radians(angle) * axis)[0]\n",
    "\n",
    "    rows, cols, _ = img.shape\n",
    "    center = (cols // 2, rows // 2)\n",
    "    focal_length = cols / (2 * np.tan(np.radians(60) / 2))\n",
    "    \n",
    "    # Build the rotation matrix\n",
    "    r_x = rotation_matrix(np.array([1, 0, 0]), pitch)\n",
    "    r_y = rotation_matrix(np.array([0, 1, 0]), yaw)\n",
    "    r_z = rotation_matrix(np.array([0, 0, 1]), roll)\n",
    "    r = np.matmul(np.matmul(r_z, r_y), r_x)\n",
    "\n",
    "    # Build the perspective transformation matrix\n",
    "    m = np.zeros((3, 4), dtype=np.float64)\n",
    "    m[:, :3] = r\n",
    "    m[:, 3] = [0, 0, focal_length]\n",
    "    m_4x4 = np.vstack((m, np.array([0, 0, 0, 1])))\n",
    "    pre_m = np.array([[1, 0, 0, -center[0]], [0, 1, 0, -center[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    m = np.matmul(pre_m, m_4x4)[:3]\n",
    "    \n",
    "    # Apply the perspective transformation\n",
    "    img_warped = cv2.warpPerspective(img, m, (cols, rows))\n",
    "    display_image(img_warped)\n",
    "# Load your input image\n",
    "#img = cv2.imread('path/to/your/image.jpg')\n",
    "img = image_p\n",
    "\n",
    "# Create widgets for the angles\n",
    "pitch_slider = widgets.FloatSlider(min=-10, max=10, step=0.5, value=0, description='Pitch')\n",
    "yaw_slider = widgets.FloatSlider(min=-10, max=10, step=0.5, value=0, description='Yaw')\n",
    "roll_slider = widgets.FloatSlider(min=-10, max=10, step=0.5, value=0, description='Roll')\n",
    "\n",
    "widgets.interact(warp_perspective, pitch=pitch_slider, yaw=yaw_slider, roll=roll_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe432aad",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.512Z"
    }
   },
   "outputs": [],
   "source": [
    "def square_off(bbox, f=0.5):\n",
    "    x1 = bbox[[0, 1], 0].mean()\n",
    "    x2 = bbox[[2, 3], 0].mean()\n",
    "\n",
    "    y1 = bbox[[0, 2], 1].mean()\n",
    "    y2 = bbox[[1, 3], 1].mean()\n",
    "\n",
    "    out = np.array(\n",
    "        [\n",
    "            [x1, y1],\n",
    "            [x1, y2],\n",
    "            [x2, y1],\n",
    "            [x2, y2],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (1 - f) * bbox + f * out\n",
    "\n",
    "\n",
    "# Define a 2D numpy array bounding box\n",
    "src_bbox = digit_bboxes[\"watts\"].astype(np.float32)\n",
    "src_bbox\n",
    "\n",
    "dst_bbox = square_off(src_bbox, 1)\n",
    "# dst_bbox = src_bbox\n",
    "dst_bbox\n",
    "\n",
    "# Define the destination bounding box\n",
    "# dst_bbox = np.array([[100, 100], [200, 100], [200, 200], [100, 200]], dtype=np.float32)\n",
    "\n",
    "# Calculate the perspective transformation matrix\n",
    "M = cv2.getPerspectiveTransform(src_bbox, dst_bbox)\n",
    "M\n",
    "\n",
    "# Now you can use M to transform the original image using cv2.warpPerspective\n",
    "rows, cols, _ = image_p.shape\n",
    "display_image(image_p)\n",
    "display_image(cv2.warpPerspective(image_p, M, (cols, rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24e8f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.512Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            digit_bboxes[e]\n",
    "            for e in [\n",
    "                \"speed\",\n",
    "                # \"mph\",\n",
    "                # \"watts\",\n",
    "                \"cadence\",\n",
    "                \"distance\",\n",
    "                # \"time\",\n",
    "                \"calories\",\n",
    "                # \"targets\",\n",
    "                # \"heart\",\n",
    "                # \"rate\",\n",
    "            ]\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"x\", \"y\"],\n",
    ")\n",
    "# df\n",
    "# ?linregress\n",
    "slope, *rest = linregress(df.x.to_numpy(), df.y.to_numpy())\n",
    "\n",
    "p9.ggplot(df, p9.aes(\"x\", \"-y\")) + p9.geom_point() + p9.geom_smooth(method=\"lm\")\n",
    "\n",
    "\n",
    "def warp_perspective(img, angle=0, scale=1, tx=0, ty=0):\n",
    "    # clear_output(wait=True)\n",
    "\n",
    "    rows, cols, _ = img.shape\n",
    "    center = (cols // 2, rows // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotation_matrix[:, 2] += [tx, ty]\n",
    "\n",
    "    return cv2.warpAffine(img, rotation_matrix, (cols, rows))\n",
    "\n",
    "\n",
    "def crop_image(image, bbox):\n",
    "    \"\"\"\n",
    "    Crop an image (in numpy representation) to the given bounding box.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The input image in numpy format (height, width, channels)\n",
    "    - bbox (list or tuple): The bounding box as (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    Returns:\n",
    "    - cropped_image (numpy.ndarray): The cropped image\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "width = df.x.max() - df.x.min()\n",
    "height = df.y.max() - df.y.min()\n",
    "(width, height)\n",
    "bbox = np.round(\n",
    "    np.asarray(\n",
    "        [\n",
    "            df.x.min() - 0.05 * width,\n",
    "            df.y.min() - 0.05 * height,\n",
    "            df.x.max() + 0.10 * width,\n",
    "            df.y.max() + 0.45 * height,\n",
    "        ]\n",
    "    )\n",
    ").astype(int)\n",
    "\n",
    "image_p_c = crop_image(image_p, bbox)\n",
    "\n",
    "\n",
    "display_image(image_p_c)\n",
    "\n",
    "angle_rad = np.arctan(slope)\n",
    "angle_deg = np.degrees(angle_rad)\n",
    "(slope, angle_rad, angle_deg)\n",
    "\n",
    "display_image(warp_perspective(image_p_c, angle=angle_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abbf40",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.513Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x.keys()\n",
    "\n",
    "pd.DataFrame(x[\"predictions\"][0])\n",
    "\n",
    "plt.imshow(x[\"visualization\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892e130",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.514Z"
    }
   },
   "outputs": [],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc01488",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.514Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Iterate through all the image files in the directory\n",
    "for fname in image_directory.glob(\"*\"):\n",
    "    if not fname.suffix in {'.png', '.jpg', '.jpeg'}:\n",
    "        continue\n",
    "    \n",
    "    print(f\"On image file [{fname}]\")\n",
    "\n",
    "    # Run EasyOCR on the image\n",
    "    results = reader.readtext(str(fname))\n",
    "\n",
    "    print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fbd8bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.515Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmocr.apis import MMOCRInferencer\n",
    "infer = MMOCRInferencer(rec='svtr-small')\n",
    "result = infer(root / \"frames/output_001.png\", save_vis=True, return_vis=True)\n",
    "print(result['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3cf06",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-09T22:56:01.515Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(result['visualization'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402b55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (exercise-machina-3.10.11)",
   "language": "python",
   "name": "exercise-machina-3.10.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
